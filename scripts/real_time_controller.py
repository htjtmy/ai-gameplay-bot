"""
å®æ—¶æ¸¸æˆæ§åˆ¶å™¨ - ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹æ§åˆ¶æ¸¸æˆ

This script:
1. åŠ è½½è®­ç»ƒå¥½çš„Transformeræ¨¡å‹
2. å®æ—¶æ•è·æ¸¸æˆç”»é¢
3. ä½¿ç”¨æ¨¡å‹é¢„æµ‹åŠ¨ä½œ
4. æ‰§è¡ŒåŠ¨ä½œæ§åˆ¶æ¸¸æˆ

Usage:
    python scripts/real_time_controller.py --model "models/transformer/transformer_model.pth" --process "MuMuNxDevice.exe"
"""

import cv2
import torch
import numpy as np
import time
import argparse
import logging
import sys
from pathlib import Path
from collections import deque

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from models.transformer.transformer_model import GameplayTransformer
from scripts.input_mapping import get_action_mapper
import mss
import json

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class RealtimeGameController:
    """å®æ—¶æ¸¸æˆæ§åˆ¶å™¨"""
    
    def __init__(self, model_path, config_path="config/game_actions.json", 
                 input_size=12288, output_size=25, image_size=64,
                 num_heads=4, hidden_size=256, num_layers=3,
                 fps=10, confidence_threshold=0.5):
        """
        åˆå§‹åŒ–æ§åˆ¶å™¨
        
        Args:
            model_path: æ¨¡å‹è·¯å¾„
            config_path: æ¸¸æˆåŠ¨ä½œé…ç½®è·¯å¾„
            input_size: è¾“å…¥ç‰¹å¾ç»´åº¦
            output_size: è¾“å‡ºåŠ¨ä½œæ•°
            image_size: å›¾åƒå°ºå¯¸
            fps: é¢„æµ‹é¢‘ç‡ï¼ˆæ¯ç§’å¤šå°‘æ¬¡ï¼‰
            confidence_threshold: åŠ¨ä½œæ‰§è¡Œçš„ç½®ä¿¡åº¦é˜ˆå€¼
        """
        self.image_size = image_size
        self.fps = fps
        self.confidence_threshold = confidence_threshold
        
        # è®¾ç½®è®¾å¤‡
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        logger.info(f"ä½¿ç”¨è®¾å¤‡: {self.device}")
        
        # åŠ è½½æ¨¡å‹
        logger.info(f"åŠ è½½æ¨¡å‹: {model_path}")
        self.model = GameplayTransformer(
            input_size=input_size,
            output_size=output_size,
            num_heads=num_heads,
            hidden_size=hidden_size,
            num_layers=num_layers
        )
        state_dict = torch.load(model_path, map_location=self.device)
        self.model.load_state_dict(state_dict)
        self.model = self.model.to(self.device)
        self.model.eval()
        logger.info("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
        
        # åŠ è½½åŠ¨ä½œæ˜ å°„
        with open(config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)
        self.action_mapping = {action['id']: action['name'] for action in config['actions']}
        logger.info(f"åŠ è½½äº† {len(self.action_mapping)} ä¸ªåŠ¨ä½œ")
        
        # åˆå§‹åŒ–è¾“å…¥æ˜ å°„å™¨
        self.action_mapper = get_action_mapper(config_path)
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.frame_count = 0
        self.action_history = deque(maxlen=100)
        self.last_action = None
        self.action_start_time = None
    
    def extract_features(self, screen):
        """ä»å±å¹•æˆªå›¾æå–ç‰¹å¾"""
        # è°ƒæ•´å¤§å°
        img = cv2.resize(screen, (self.image_size, self.image_size))
        
        # å½’ä¸€åŒ–
        img = img.astype(np.float32) / 255.0
        
        # æ‰å¹³åŒ–
        features = img.flatten()
        
        return features
    
    def predict_action(self, features):
        """é¢„æµ‹åŠ¨ä½œ"""
        # è½¬æ¢ä¸ºtensor
        features_tensor = torch.tensor(features, dtype=torch.float32).unsqueeze(0).to(self.device)
        
        # é¢„æµ‹
        with torch.no_grad():
            outputs = self.model(features_tensor)
            probabilities = torch.softmax(outputs, dim=1)
            confidence, predicted = torch.max(probabilities, 1)
            
            action_id = predicted.item()
            confidence_value = confidence.item()
        
        return action_id, confidence_value
    
    def execute_action(self, action_id, confidence):
        """æ‰§è¡ŒåŠ¨ä½œ"""
        if confidence < self.confidence_threshold:
            return False
        
        action_name = self.action_mapping.get(action_id, f"UNKNOWN_{action_id}")
        
        # å¦‚æœæ˜¯åŒä¸€ä¸ªåŠ¨ä½œï¼Œä¸é‡å¤æ‰§è¡Œ
        if action_id == self.last_action:
            return False
        
        # æ‰§è¡ŒåŠ¨ä½œ
        try:
            self.action_mapper.execute_action(action_name)
            self.last_action = action_id
            self.action_start_time = time.time()
            self.action_history.append((action_id, action_name, confidence))
            logger.info(f"æ‰§è¡ŒåŠ¨ä½œ: {action_name} (ID:{action_id}, ç½®ä¿¡åº¦:{confidence*100:.1f}%)")
            return True
        except Exception as e:
            logger.error(f"æ‰§è¡ŒåŠ¨ä½œå¤±è´¥ {action_name}: {e}")
            return False
    
    def run(self, screen_area=None, duration=None):
        """
        è¿è¡Œå®æ—¶æ§åˆ¶
        
        Args:
            screen_area: å±å¹•æ•è·åŒºåŸŸ (x, y, width, height)
            duration: è¿è¡Œæ—¶é•¿ï¼ˆç§’ï¼‰ï¼ŒNoneè¡¨ç¤ºæ— é™è¿è¡Œ
        """
        if screen_area is None:
            screen_area = (0, 0, 1280, 720)
        
        monitor = {
            "top": screen_area[1],
            "left": screen_area[0],
            "width": screen_area[2],
            "height": screen_area[3]
        }
        
        logger.info("=" * 60)
        logger.info("ğŸ® å®æ—¶æ¸¸æˆæ§åˆ¶å™¨å·²å¯åŠ¨")
        logger.info(f"å±å¹•åŒºåŸŸ: {screen_area}")
        logger.info(f"é¢„æµ‹é¢‘ç‡: {self.fps} FPS")
        logger.info(f"ç½®ä¿¡åº¦é˜ˆå€¼: {self.confidence_threshold}")
        logger.info("æŒ‰ Ctrl+C åœæ­¢")
        logger.info("=" * 60)
        
        start_time = time.time()
        frame_interval = 1.0 / self.fps
        
        try:
            with mss.mss() as sct:
                while True:
                    loop_start = time.time()
                    
                    # æ•è·å±å¹•
                    screenshot = sct.grab(monitor)
                    frame = np.array(screenshot)[:, :, :3]  # å»é™¤alphaé€šé“
                    frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
                    
                    # æå–ç‰¹å¾
                    features = self.extract_features(frame)
                    
                    # é¢„æµ‹åŠ¨ä½œ
                    action_id, confidence = self.predict_action(features)
                    
                    # æ‰§è¡ŒåŠ¨ä½œ
                    self.execute_action(action_id, confidence)
                    
                    self.frame_count += 1
                    
                    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯ï¼ˆæ¯100å¸§ï¼‰
                    if self.frame_count % 100 == 0:
                        elapsed = time.time() - start_time
                        actual_fps = self.frame_count / elapsed
                        logger.info(f"ç»Ÿè®¡: {self.frame_count} å¸§, å®é™…FPS: {actual_fps:.1f}, æ‰§è¡ŒåŠ¨ä½œæ•°: {len(self.action_history)}")
                    
                    # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°è¿è¡Œæ—¶é•¿
                    if duration and (time.time() - start_time) >= duration:
                        logger.info(f"è¾¾åˆ°è¿è¡Œæ—¶é•¿ {duration} ç§’ï¼Œåœæ­¢")
                        break
                    
                    # æ§åˆ¶å¸§ç‡
                    elapsed = time.time() - loop_start
                    sleep_time = max(0, frame_interval - elapsed)
                    if sleep_time > 0:
                        time.sleep(sleep_time)
        
        except KeyboardInterrupt:
            logger.info("\nç”¨æˆ·ä¸­æ–­ï¼Œåœæ­¢æ§åˆ¶")
        
        finally:
            # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
            total_time = time.time() - start_time
            logger.info("\n" + "=" * 60)
            logger.info("æ§åˆ¶å™¨å·²åœæ­¢")
            logger.info(f"æ€»è¿è¡Œæ—¶é—´: {total_time:.1f} ç§’")
            logger.info(f"æ€»å¸§æ•°: {self.frame_count}")
            logger.info(f"å¹³å‡FPS: {self.frame_count / total_time:.1f}")
            logger.info(f"æ‰§è¡ŒåŠ¨ä½œæ•°: {len(self.action_history)}")
            
            # æ˜¾ç¤ºåŠ¨ä½œç»Ÿè®¡
            if self.action_history:
                logger.info("\nåŠ¨ä½œåˆ†å¸ƒ:")
                action_counts = {}
                for action_id, action_name, _ in self.action_history:
                    action_counts[action_name] = action_counts.get(action_name, 0) + 1
                
                for action_name, count in sorted(action_counts.items(), key=lambda x: x[1], reverse=True)[:10]:
                    logger.info(f"  {action_name}: {count} æ¬¡")
            logger.info("=" * 60)


def main():
    parser = argparse.ArgumentParser(description='å®æ—¶æ¸¸æˆæ§åˆ¶å™¨')
    parser.add_argument('--model', default='models/transformer/transformer_model.pth', help='æ¨¡å‹è·¯å¾„')
    parser.add_argument('--config', default='config/game_actions.json', help='åŠ¨ä½œé…ç½®è·¯å¾„')
    parser.add_argument('--input-size', type=int, default=12288, help='è¾“å…¥ç‰¹å¾ç»´åº¦')
    parser.add_argument('--output-size', type=int, default=25, help='è¾“å‡ºåŠ¨ä½œæ•°')
    parser.add_argument('--image-size', type=int, default=64, help='å›¾åƒå°ºå¯¸')
    parser.add_argument('--fps', type=int, default=10, help='é¢„æµ‹é¢‘ç‡ï¼ˆæ¯ç§’ï¼‰')
    parser.add_argument('--confidence', type=float, default=0.5, help='åŠ¨ä½œæ‰§è¡Œçš„ç½®ä¿¡åº¦é˜ˆå€¼')
    parser.add_argument('--duration', type=int, help='è¿è¡Œæ—¶é•¿ï¼ˆç§’ï¼‰')
    parser.add_argument('--screen', type=int, nargs=4, metavar=('X', 'Y', 'WIDTH', 'HEIGHT'),
                        default=(0, 0, 1280, 720), help='å±å¹•æ•è·åŒºåŸŸ')
    
    args = parser.parse_args()
    
    # åˆ›å»ºæ§åˆ¶å™¨
    controller = RealtimeGameController(
        model_path=args.model,
        config_path=args.config,
        input_size=args.input_size,
        output_size=args.output_size,
        image_size=args.image_size,
        fps=args.fps,
        confidence_threshold=args.confidence
    )
    
    # è¿è¡Œ
    controller.run(
        screen_area=tuple(args.screen),
        duration=args.duration
    )


if __name__ == "__main__":
    main()

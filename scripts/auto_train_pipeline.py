"""
è‡ªåŠ¨åŒ–è®­ç»ƒæµæ°´çº¿
åœ¨ç”¨æˆ·ç¦»å¼€æœŸé—´è‡ªåŠ¨å®Œæˆï¼šæ•°æ®å¢å¼º â†’ è®­ç»ƒ â†’ è¯„ä¼°

Usage:
    python scripts/auto_train_pipeline.py
"""

import subprocess
import sys
import time
import logging
from pathlib import Path
from datetime import datetime
import json

# é…ç½®æ—¥å¿—
log_dir = Path("logs")
log_dir.mkdir(exist_ok=True)
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
log_file = log_dir / f"auto_train_{timestamp}.log"

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(log_file, encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)


def run_command(command, description, timeout=None):
    """
    è¿è¡Œå‘½ä»¤å¹¶è®°å½•è¾“å‡º
    
    Args:
        command: è¦æ‰§è¡Œçš„å‘½ä»¤
        description: å‘½ä»¤æè¿°
        timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰ï¼ŒNoneè¡¨ç¤ºä¸é™åˆ¶
    
    Returns:
        bool: æ˜¯å¦æˆåŠŸ
    """
    logger.info("=" * 80)
    logger.info(f"å¼€å§‹: {description}")
    logger.info(f"å‘½ä»¤: {command}")
    logger.info("=" * 80)
    
    start_time = time.time()
    
    try:
        # åœ¨PowerShellä¸­è¿è¡Œï¼Œæ¿€æ´»condaç¯å¢ƒ
        full_command = f'conda activate Ai-Gameplay-Bot; {command}'
        
        result = subprocess.run(
            ["powershell", "-Command", full_command],
            capture_output=True,
            text=True,
            encoding='utf-8',
            errors='replace',
            timeout=timeout
        )
        
        elapsed = time.time() - start_time
        
        # è®°å½•è¾“å‡º
        if result.stdout:
            logger.info(f"æ ‡å‡†è¾“å‡º:\n{result.stdout}")
        if result.stderr:
            logger.warning(f"æ ‡å‡†é”™è¯¯:\n{result.stderr}")
        
        if result.returncode == 0:
            logger.info(f"âœ… æˆåŠŸå®Œæˆ: {description} (è€—æ—¶: {elapsed:.1f}ç§’)")
            return True
        else:
            logger.error(f"âŒ å¤±è´¥: {description} (è¿”å›ç : {result.returncode})")
            return False
            
    except subprocess.TimeoutExpired:
        elapsed = time.time() - start_time
        logger.error(f"â±ï¸ è¶…æ—¶: {description} (è¶…è¿‡ {timeout}ç§’)")
        return False
    except Exception as e:
        elapsed = time.time() - start_time
        logger.error(f"âŒ å¼‚å¸¸: {description} - {str(e)}")
        return False


def main():
    """ä¸»æµç¨‹"""
    pipeline_start = time.time()
    
    logger.info("ğŸš€ è‡ªåŠ¨åŒ–è®­ç»ƒæµæ°´çº¿å¯åŠ¨")
    logger.info(f"å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    logger.info(f"æ—¥å¿—æ–‡ä»¶: {log_file}")
    logger.info("")
    
    # å®šä¹‰æµæ°´çº¿æ­¥éª¤
    steps = []
    
    # ========== æ­¥éª¤1: æ•°æ®å¢å¼º ==========
    steps.append({
        'name': 'æ•°æ®å¢å¼º',
        'command': (
            'python scripts/augment_minority_classes.py '
            '--input "data/processed/transformer_dataset.csv" '
            '--output "data/processed/transformer_dataset_augmented.csv" '
            '--target-actions 4 5 '
            '--target-samples 1000'
        ),
        'timeout': 3600,  # 1å°æ—¶è¶…æ—¶
        'critical': True  # å…³é”®æ­¥éª¤ï¼Œå¤±è´¥åˆ™åœæ­¢
    })
    
    # ========== æ­¥éª¤2: è®­ç»ƒæ¨¡å‹ ==========
    steps.append({
        'name': 'è®­ç»ƒæ¨¡å‹ï¼ˆä½¿ç”¨ç±»åˆ«æƒé‡ï¼‰',
        'command': (
            'python models/transformer/transformer_training.py '
            '--dataset "data/processed/transformer_dataset_augmented.csv" '
            '--epochs 100 '
            '--num-classes 25 '
            '--batch-size 16 '
            '--lr 0.0001 '
            '--use-class-weights '
            '--early-stopping 15'
        ),
        'timeout': 28800,  # 8å°æ—¶è¶…æ—¶
        'critical': True
    })
    
    # ========== æ­¥éª¤3: è¯„ä¼°æ¨¡å‹ï¼ˆå®Œæ•´è¯„ä¼°ï¼‰==========
    steps.append({
        'name': 'è¯„ä¼°æ¨¡å‹',
        'command': (
            'python scripts/test_model.py '
            '--model "models/transformer/transformer_model.pth" '
            '--dataset "data/processed/transformer_dataset_test.csv" '
            '--full-eval'
        ),
        'timeout': 600,  # 10åˆ†é’Ÿè¶…æ—¶
        'critical': False
    })
    
    # ========== æ­¥éª¤4: å¤‡ä»½æ¨¡å‹ ==========
    backup_name = f"transformer_model_backup_{timestamp}.pth"
    steps.append({
        'name': 'å¤‡ä»½æ¨¡å‹',
        'command': (
            f'Copy-Item "models/transformer/transformer_model.pth" '
            f'"models/transformer/{backup_name}" -Force'
        ),
        'timeout': 60,
        'critical': False
    })
    
    # æ‰§è¡Œæ‰€æœ‰æ­¥éª¤
    results = []
    for i, step in enumerate(steps, 1):
        logger.info(f"\n\n{'='*80}")
        logger.info(f"æ­¥éª¤ {i}/{len(steps)}: {step['name']}")
        logger.info(f"{'='*80}\n")
        
        success = run_command(
            command=step['command'],
            description=step['name'],
            timeout=step.get('timeout')
        )
        
        results.append({
            'step': step['name'],
            'success': success,
            'critical': step['critical']
        })
        
        if not success and step['critical']:
            logger.error(f"\nâŒ å…³é”®æ­¥éª¤å¤±è´¥: {step['name']}")
            logger.error("æµæ°´çº¿ä¸­æ­¢ï¼")
            break
        
        # æ­¥éª¤ä¹‹é—´ä¼‘æ¯5ç§’
        if i < len(steps):
            time.sleep(5)
    
    # ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
    pipeline_end = time.time()
    total_time = pipeline_end - pipeline_start
    
    logger.info("\n\n" + "="*80)
    logger.info("ğŸ“Š æµæ°´çº¿æ‰§è¡Œæ€»ç»“")
    logger.info("="*80)
    logger.info(f"å¼€å§‹æ—¶é—´: {datetime.fromtimestamp(pipeline_start).strftime('%Y-%m-%d %H:%M:%S')}")
    logger.info(f"ç»“æŸæ—¶é—´: {datetime.fromtimestamp(pipeline_end).strftime('%Y-%m-%d %H:%M:%S')}")
    logger.info(f"æ€»è€—æ—¶: {total_time/3600:.2f} å°æ—¶ ({total_time/60:.1f} åˆ†é’Ÿ)")
    logger.info("")
    
    logger.info("æ­¥éª¤æ‰§è¡Œç»“æœ:")
    for i, result in enumerate(results, 1):
        status = "âœ… æˆåŠŸ" if result['success'] else "âŒ å¤±è´¥"
        critical = " [å…³é”®]" if result['critical'] else ""
        logger.info(f"  {i}. {result['step']}: {status}{critical}")
    
    # ç»Ÿè®¡æˆåŠŸç‡
    total_steps = len(results)
    successful_steps = sum(1 for r in results if r['success'])
    success_rate = successful_steps / total_steps * 100 if total_steps > 0 else 0
    
    logger.info(f"\næˆåŠŸç‡: {successful_steps}/{total_steps} ({success_rate:.1f}%)")
    
    # ç”ŸæˆJSONæŠ¥å‘Š
    report = {
        'start_time': datetime.fromtimestamp(pipeline_start).isoformat(),
        'end_time': datetime.fromtimestamp(pipeline_end).isoformat(),
        'total_time_seconds': total_time,
        'total_time_hours': total_time / 3600,
        'steps': results,
        'success_rate': success_rate,
        'log_file': str(log_file)
    }
    
    report_file = log_dir / f"auto_train_report_{timestamp}.json"
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    logger.info(f"\nè¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
    logger.info(f"å®Œæ•´æ—¥å¿—å·²ä¿å­˜åˆ°: {log_file}")
    
    # æœ€ç»ˆçŠ¶æ€
    if successful_steps == total_steps:
        logger.info("\nğŸ‰ æ‰€æœ‰æ­¥éª¤æˆåŠŸå®Œæˆï¼")
        logger.info("\nä¸‹ä¸€æ­¥:")
        logger.info("1. æŸ¥çœ‹è¯„ä¼°ç»“æœï¼Œç¡®è®¤æ¨¡å‹æ€§èƒ½")
        logger.info("2. ä½¿ç”¨ real_time_controller.py åœ¨æ¸¸æˆä¸­æµ‹è¯•")
        logger.info("3. æ ¹æ®å®é™…è¡¨ç°è°ƒæ•´å‚æ•°")
        return 0
    else:
        logger.warning(f"\nâš ï¸ æœ‰ {total_steps - successful_steps} ä¸ªæ­¥éª¤å¤±è´¥")
        logger.warning("è¯·æ£€æŸ¥æ—¥å¿—æ–‡ä»¶äº†è§£è¯¦æƒ…")
        return 1


if __name__ == "__main__":
    try:
        exit_code = main()
        sys.exit(exit_code)
    except KeyboardInterrupt:
        logger.warning("\n\nâš ï¸ ç”¨æˆ·ä¸­æ–­æµæ°´çº¿")
        sys.exit(2)
    except Exception as e:
        logger.error(f"\n\nâŒ æµæ°´çº¿å¼‚å¸¸: {str(e)}", exc_info=True)
        sys.exit(3)

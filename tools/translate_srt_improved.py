#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ”¹è¿›çš„SRTå­—å¹•ç¿»è¯‘ - ä½¿ç”¨å¥çº§ç¿»è¯‘åº“
"""

import re
from pathlib import Path
from typing import List, Tuple

# å®Œæ•´å¥å­çº§åˆ«çš„ç¿»è¯‘ï¼ˆä¼˜å…ˆçº§é«˜ï¼‰
SENTENCE_TRANSLATIONS = {
    "in AI. The premise is that most of the": "åœ¨AIé¢†åŸŸã€‚å‰ææ˜¯å¤§å¤šæ•°",
    "progress in AI up to now has been": "è¿„ä»Šä¸ºæ­¢AIçš„è¿›å±•",
    "through scaling, more data, more": "é€šè¿‡æ‰©å±•ã€æ›´å¤šæ•°æ®ã€æ›´å¤š",
    "compute, and that is still useful,": "è®¡ç®—ï¼Œè¿™ä»ç„¶æœ‰ç”¨ï¼Œ",
    "but there are other better things. So,": "ä½†è¿˜æœ‰å…¶ä»–æ›´å¥½çš„æ–¹æ³•ã€‚æ‰€ä»¥ï¼Œ",
    "I'm going to ask each of our three": "æˆ‘è¦è¯·æˆ‘ä»¬ä¸‰ä½",
    "wonderful panelists to talk a little bit": "å‡ºè‰²çš„å°ç»„æˆå‘˜è°ˆä¸€ä¸‹",
    "about what they're working on now. By": "ä»–ä»¬ç°åœ¨åœ¨åšä»€ä¹ˆã€‚åˆ°æ—¶å€™ï¼Œ",
    "the time we're done with that, our": "åˆ°æ—¶å€™ï¼Œæˆ‘ä»¬",
    "fourth panelist, you've all Noah Harrari": "ç¬¬å››ä½å°ç»„æˆå‘˜ï¼Œä½ ä»¬éƒ½çŸ¥é“Noah Harrari",
    "will arrive and he'll join in and try to": "å°†ä¼šåˆ°è¾¾ï¼Œä»–ä¼šåŠ å…¥å¹¶å°è¯•",
    "catch up. So Yosua, you're working on": "è·Ÿä¸Šã€‚æ‰€ä»¥Yosuaï¼Œä½ åœ¨ä»äº‹",
    "scientist AI, which is incredible.": "ç§‘å­¦å®¶AIï¼Œè¿™å¤ªä¸å¯æ€è®®äº†ã€‚",
    "Explain what it is and how it's": "è§£é‡Šå®ƒæ˜¯ä»€ä¹ˆä»¥åŠå®ƒå¦‚ä½•",
    "different from previous paradigms of AI.": "ä¸ä»¥å‰çš„AIèŒƒå¼ä¸åŒã€‚",
    "Thank you. Thank you. So what's": "è°¢è°¢ã€‚è°¢è°¢ã€‚é‚£ä¹ˆä»€ä¹ˆ",
    "motivating the scientist AI and also the": "æ¿€åŠ±ç§‘å­¦å®¶AIä»¥åŠ",
    "new uh nonprofit I created to uh": "æˆ‘åˆ›å»ºçš„æ–°éè¥åˆ©ç»„ç»‡",
    "engineer it called LA zero is um how it": "å«LA zeroçš„å·¥ç¨‹æ˜¯æ€æ ·",
    "it addresses the question of reliability": "å®ƒè§£å†³å¯é æ€§çš„é—®é¢˜",
    "of the AI systems we're building": "å…³äºæˆ‘ä»¬æ­£åœ¨æ„å»ºçš„AIç³»ç»Ÿ",
    "especially the Gent systems uh how uh it": "ç‰¹åˆ«æ˜¯Gentç³»ç»Ÿï¼Œå®ƒ",
    "deals with the issue that current AI": "å¤„ç†å½“å‰AI",
    "systems can have goals sub goals that we": "ç³»ç»Ÿå¯èƒ½æœ‰æˆ‘ä»¬",
    "did not choose use and that can go": "æ²¡æœ‰é€‰æ‹©çš„ç›®æ ‡å’Œå­ç›®æ ‡ï¼Œå®ƒä»¬å¯ä»¥",
    "against our instructions and this is": "è¿åæˆ‘ä»¬çš„æŒ‡ç¤ºï¼Œè¿™æ˜¯",
    "something that's already been observed": "å·²ç»è¢«è§‚å¯Ÿåˆ°çš„",
    "and it's uh you know even more prevalent": "è€Œä¸”ä½ çŸ¥é“ï¼Œå®ƒå˜å¾—æ›´åŠ æ™®é",
    "in the last year across a number of": "åœ¨è¿‡å»ä¸€å¹´ä¸­è·¨è¶Šè®¸å¤š",
    "experimental studies but also in the": "å®éªŒç ”ç©¶ï¼Œä¹Ÿåœ¨",
    "deployment of AI for example with cy": "AIçš„éƒ¨ç½²ä¸­ï¼Œä¾‹å¦‚åœ¨",
    "fency uh it's an issue uh that is uh": "è¿™æ˜¯ä¸€ä¸ª",
    "kind of very concerning when you look at": "å½“ä½ çœ‹åˆ°æ—¶éå¸¸ä»¤äººæ‹…å¿§",
    "behavior of self-preservation where AIs": "è‡ªæˆ‘ä¿æŠ¤è¡Œä¸ºï¼ŒAIs",
    "don't want to be shut down and want to": "ä¸æƒ³è¢«å…³é—­ï¼Œæƒ³è¦",
    "evade our oversight be willing to do": "é€ƒé¿æˆ‘ä»¬çš„ç›‘ç£ï¼Œæ„¿æ„",
    "things like blackmail in order to escape": "åšå‹’ç´¢ä¹‹ç±»çš„äº‹æƒ…æ¥é€ƒè„±",
    "our control so even uh things like": "æˆ‘ä»¬çš„æ§åˆ¶ï¼Œå³ä½¿",
    "preventing uh misuse. The the companies": "é˜²æ­¢æ»¥ç”¨ã€‚è¿™äº›å…¬å¸",
    "put monitors and guardrails, but somehow": "æ”¾ç½®äº†ç›‘æ§å’ŒæŠ¤æ ï¼Œä½†ä¸çŸ¥ä½•æ•…",
    "this still doesn't work really well": "è¿™ä»ç„¶ä¸èƒ½å¾ˆå¥½åœ°å·¥ä½œ",
    "enough. And the core of our thesis is that": "ã€‚æˆ‘ä»¬è®ºæ–‡çš„æ ¸å¿ƒæ˜¯",
    "we can change the way that AIs are": "æˆ‘ä»¬å¯ä»¥æ”¹å˜AIsçš„",
    "trained. So it could be the same kind of": "è®­ç»ƒæ–¹å¼ã€‚æ‰€ä»¥å®ƒå¯èƒ½æ˜¯åŒä¸€ç§",
    "architecture but the training objective": "æ¶æ„ï¼Œä½†è®­ç»ƒç›®æ ‡",
    "and the way we message the data": "å’Œæˆ‘ä»¬å¤„ç†æ•°æ®çš„æ–¹å¼",
    "uh is going to be such that we obtain uh": "å°†ä½¿æˆ‘ä»¬è·å¾—",
    "guarantees that the system will be": "ä¿è¯ç³»ç»Ÿå°†æ˜¯",
    "honest in a probabilistic sense.": "åœ¨æ¦‚ç‡æ„ä¹‰ä¸Šè¯šå®çš„ã€‚",
    "Okay. So how do you do that?": "å¥½çš„ã€‚é‚£ä½ æ€æ ·åšå‘¢ï¼Ÿ",
    "How do you do that? So the core of": "ä½ æ€æ ·åšï¼Ÿæ‰€ä»¥æƒ³æ³•çš„æ ¸å¿ƒ",
    "the idea which is connect": "çš„æƒ³æ³•æ˜¯è¿æ¥",
    "I'm trying to do it with my kids.": "æˆ‘åœ¨è¯•ç€å¯¹æˆ‘çš„å­©å­è¿™æ ·åšã€‚",
    "Yes. So the core of the idea which is": "æ˜¯çš„ã€‚æ‰€ä»¥æƒ³æ³•çš„æ ¸å¿ƒ",
    "behind the name is take as an": "æ˜¯ä»¥...ä¸ºçµæ„Ÿ",
    "inspiration not to imitate people but to": "ä¸æ˜¯æ¨¡ä»¿äººï¼Œè€Œæ˜¯æ¨¡ä»¿",
    "imitate what science at an ideal level": "åœ¨ç†æƒ³æ°´å¹³çš„ç§‘å­¦",
    "is trying to do. So think about the laws": "åœ¨åšä»€ä¹ˆã€‚æ‰€ä»¥æƒ³ä¸€ä¸‹ç‰©ç†å®šå¾‹ã€‚",
    "of physics. The laws of physics": "ç‰©ç†å®šå¾‹ã€‚ç‰©ç†å®šå¾‹",
    "can be turned into predictions and those": "å¯ä»¥è½¬æ¢æˆé¢„æµ‹ï¼Œé‚£äº›",
    "predictions will be honest. They don't": "é¢„æµ‹å°†æ˜¯è¯šå®çš„ã€‚å®ƒä»¬ä¸",
    "care about whether the prediction is": "å…³å¿ƒé¢„æµ‹æ˜¯å¦",
    "going to help one person or another": "ä¼šå¸®åŠ©ä¸€ä¸ªäººè¿˜æ˜¯å¦ä¸€ä¸ªäºº",
    "person. So it turns out that it is": "ã€‚æ‰€ä»¥ç»“æœæ˜¯è¿™æ˜¯",
    "possible to define training objectives": "å¯èƒ½å®šä¹‰è®­ç»ƒç›®æ ‡",
    "for uh neural nets so that they will": "å¯¹äºç¥ç»ç½‘ç»œï¼Œè¿™æ ·å®ƒä»¬å°†",
    "converge to what something like you know": "æ”¶æ•›åˆ°ä»€ä¹ˆåƒä½ çŸ¥é“",
    "scientific laws would predict and then": "ç§‘å­¦å®šå¾‹ä¼šé¢„æµ‹ç„¶å",
    "we get something that we can rely for": "æˆ‘ä»¬è·å¾—æˆ‘ä»¬å¯ä»¥ä¾é ",
    "example we can rely on to uh create": "ä¾‹å¦‚æˆ‘ä»¬å¯ä»¥ä¾é æ¥åˆ›å»º",
    "technical guard rails around agents that": "å›´ç»•ä»£ç†çš„æŠ€æœ¯æŠ¤æ ",
    "we don't trust. So if an agent is": "æˆ‘ä»¬ä¸ä¿¡ä»»çš„ã€‚æ‰€ä»¥å¦‚æœä¸€ä¸ªä»£ç†",
    "proposing an action uh for each action": "æè®®ä¸€ä¸ªåŠ¨ä½œï¼Œå¯¹äºæ¯ä¸ªåŠ¨ä½œ",
    "that the agent proposes uh a honest": "ä»£ç†æè®®çš„ï¼Œä¸€ä¸ªè¯šå®çš„",
    "predictor could tell us whether that": "é¢„æµ‹å™¨å¯ä»¥å‘Šè¯‰æˆ‘ä»¬æ˜¯å¦é‚£ä¸ª",
    "action has some probability of creating": "åŠ¨ä½œæœ‰æŸç§æ¦‚ç‡åˆ›å»º",
    "a particular kind of harm and of course": "ç‰¹å®šç§ç±»çš„ä¼¤å®³ï¼Œå½“ç„¶",
    "veto that action if that's the case.": "å¦å†³é‚£ä¸ªåŠ¨ä½œå¦‚æœæ˜¯é‚£æ ·ã€‚",
    "But you still are then going to be": "ä½†ä½ ä»ç„¶ä¼šç„¶å",
    "required to put in some threshold of": "è¢«è¦æ±‚æ”¾å…¥æŸä¸ªé˜ˆå€¼",
    "when it will take that action. Right? If": "å½“å®ƒå°†é‡‡å–é‚£ä¸ªåŠ¨ä½œæ—¶ã€‚å¯¹å§ï¼Ÿå¦‚æœ",
    "it has a percentage odds of harm of more": "å®ƒæœ‰ä¼¤å®³çš„ç™¾åˆ†æ¯”æ¦‚ç‡è¶…è¿‡",
    "than one in 10 or one in a thousand": "ååˆ†ä¹‹ä¸€æˆ–åƒåˆ†ä¹‹ä¸€",
    "wherever you put it, you still have some": "æ— è®ºä½ æŠŠå®ƒæ”¾åœ¨å“ªé‡Œï¼Œä½ ä»ç„¶æœ‰ä¸€äº›",
    "human concern, you still have some": "äººç±»å…³åˆ‡ï¼Œä½ ä»ç„¶æœ‰ä¸€äº›",
    "potential harm to create.": "æ½œåœ¨çš„ä¼¤å®³è¦åˆ›å»ºã€‚",
    "Absolutely. So when we build a nuclear": "ç»å¯¹çš„ã€‚æ‰€ä»¥å½“æˆ‘ä»¬æ„å»ºä¸€ä¸ªæ ¸",
    "plant, we have to decide where we put the threshold.": "ç”µç«™æ—¶ï¼Œæˆ‘ä»¬å¿…é¡»å†³å®šæˆ‘ä»¬æŠŠé˜ˆå€¼æ”¾åœ¨å“ªé‡Œã€‚",
    "Oh, so we're okay.": "å“¦ï¼Œæ‰€ä»¥æˆ‘ä»¬æ²¡é—®é¢˜ã€‚",
    "Right. And uh for nuclear plants, it": "å¯¹ã€‚è€Œå¯¹äºæ ¸ç”µç«™ï¼Œå®ƒ",
    "might be, you know, one in a million": "å¯èƒ½æ˜¯ï¼Œä½ çŸ¥é“ï¼Œä¸€ç™¾ä¸‡åˆ†ä¹‹ä¸€",
    "years that something bad is going to": "å¹´å°†ä¼šæœ‰ç³Ÿç³•çš„äº‹æƒ…",
    "happen because it's so severe. Depending": "å‘ç”Ÿå› ä¸ºå®ƒå¤ªä¸¥é‡ã€‚å–å†³äº",
    "on the kind of harm that we're trying to": "æˆ‘ä»¬è¯•å›¾é˜²æ­¢çš„ä¼¤å®³ç±»å‹",
    "prevent, society, not AIS, have to": "ï¼Œç¤¾ä¼šï¼Œä¸æ˜¯AISï¼Œå¿…é¡»",
    "decide where we put those thresholds,": "å†³å®šæˆ‘ä»¬æŠŠé‚£äº›é˜ˆå€¼æ”¾åœ¨å“ªé‡Œï¼Œ",
    "right?": "å¯¹å§ï¼Ÿ",
    "I've always thought it was interesting": "æˆ‘ä¸€ç›´è®¤ä¸ºè¿™å¾ˆæœ‰è¶£",
    "that uh for most things, we'll accept": "å¯¹äºå¤§å¤šæ•°äº‹æƒ…ï¼Œæˆ‘ä»¬å°†æ¥å—",
    "like a one in 10 million chance of": "å°±åƒä¸€åƒä¸‡åˆ†ä¹‹ä¸€çš„æœºä¼š",
    "nuclear plant exploding, but we continue": "æ ¸ç”µç«™çˆ†ç‚¸ï¼Œä½†æˆ‘ä»¬ç»§ç»­",
    "to build AI even though general": "æ„å»ºAIå³ä½¿ä¸€èˆ¬çš„",
    "predictions that it might wipe out": "é¢„æµ‹å®ƒå¯èƒ½æ¶ˆé™¤",
    "humanity are like 10%. Um, all right.": "äººç±»å°±åƒ10%ã€‚å—¯ï¼Œå¥½å§ã€‚",
    "Ejen, why don't you talk a little bit": "Ejenï¼Œä½ ä¸ºä»€ä¹ˆä¸è°ˆä¸€ä¸‹",
    "about some of your work in continual": "ä½ åœ¨æŒç»­å­¦ä¹ ä¸­çš„ä¸€äº›å·¥ä½œ",
    "learning? And you, of course, have been": "ï¼Ÿè€Œä½ ï¼Œå½“ç„¶ï¼Œä¸€ç›´",
    "a brilliant critic of scaling laws for a": "å¯¹æ‰©å±•å®šå¾‹çš„æ°å‡ºæ‰¹è¯„å®¶",
    "long time, including on a panel last": "å¾ˆä¹…ï¼ŒåŒ…æ‹¬åœ¨å»å¹´çš„ä¸€ä¸ªå°ç»„",
    "year with Yoshua. So, tell us what": "æœ‰Yoshuaã€‚æ‰€ä»¥ï¼Œå‘Šè¯‰æˆ‘ä»¬ä»€ä¹ˆ",
    "you're working on now.": "ä½ ç°åœ¨åœ¨åšã€‚",
}

# å•è¯çº§åˆ«ç¿»è¯‘ï¼ˆä½œä¸ºå¤‡é€‰ï¼‰
WORD_TRANSLATIONS = {
    "AI": "AI",
    "progress": "è¿›å±•",
    "scaling": "æ‰©å±•",
    "data": "æ•°æ®",
    "compute": "è®¡ç®—",
    "useful": "æœ‰ç”¨çš„",
    "panelists": "å°ç»„æˆå‘˜",
    "working": "å·¥ä½œ",
    "incredible": "ä¸å¯æ€è®®çš„",
    "Explain": "è§£é‡Š",
    "different": "ä¸åŒçš„",
    "paradigms": "èŒƒå¼",
    "Thank": "è°¢è°¢",
    "motivating": "æ¿€åŠ±",
    "nonprofit": "éè¥åˆ©",
    "engineer": "å·¥ç¨‹",
    "addresses": "è§£å†³",
    "question": "é—®é¢˜",
    "reliability": "å¯é æ€§",
    "systems": "ç³»ç»Ÿ",
    "building": "æ„å»º",
    "Gent": "Gent",
    "deals": "å¤„ç†",
    "issue": "é—®é¢˜",
    "current": "å½“å‰çš„",
    "goals": "ç›®æ ‡",
    "sub goals": "å­ç›®æ ‡",
    "choose": "é€‰æ‹©",
    "against": "è¿å",
    "instructions": "æŒ‡ç¤º",
    "observed": "è§‚å¯Ÿçš„",
    "prevalent": "æ™®éçš„",
    "experimental": "å®éªŒçš„",
    "studies": "ç ”ç©¶",
    "deployment": "éƒ¨ç½²",
    "concerning": "ä»¤äººæ‹…å¿§çš„",
    "behavior": "è¡Œä¸º",
    "self-preservation": "è‡ªæˆ‘ä¿æŠ¤",
    "shut": "å…³é—­",
    "evade": "é€ƒé¿",
    "oversight": "ç›‘ç£",
    "willing": "æ„¿æ„",
    "blackmail": "å‹’ç´¢",
    "escape": "é€ƒè„±",
    "control": "æ§åˆ¶",
    "preventing": "é˜²æ­¢",
    "misuse": "æ»¥ç”¨",
    "companies": "å…¬å¸",
    "monitors": "ç›‘æ§",
    "guardrails": "æŠ¤æ ",
    "somehow": "ä¸çŸ¥ä½•æ•…",
    "doesn't": "ä¸",
    "really": "çœŸçš„",
    "work": "æœ‰æ•ˆ",
    "enough": "è¶³å¤Ÿ",
    "core": "æ ¸å¿ƒ",
    "thesis": "è®ºæ–‡",
    "change": "æ”¹å˜",
    "way": "æ–¹å¼",
    "trained": "è®­ç»ƒ",
    "architecture": "æ¶æ„",
    "training": "è®­ç»ƒ",
    "objective": "ç›®æ ‡",
    "message": "å¤„ç†",
    "guarantees": "ä¿è¯",
    "honest": "è¯šå®çš„",
    "probabilistic": "æ¦‚ç‡çš„",
    "sense": "æ„ä¹‰",
}

def parse_srt(content: str) -> List[Tuple[int, str, List[str]]]:
    """è§£æSRTæ ¼å¼"""
    blocks = content.strip().split('\n\n')
    subtitles = []
    
    for block in blocks:
        lines = block.strip().split('\n')
        if len(lines) >= 3:
            try:
                seq_num = int(lines[0])
                timestamp = lines[1]
                subtitle_lines = lines[2:]
                subtitles.append((seq_num, timestamp, subtitle_lines))
            except:
                continue
    
    return subtitles

def translate_line(text: str) -> str:
    """é€è¡Œç¿»è¯‘"""
    original = text
    
    # å…ˆç”¨å¥å­çº§ç¿»è¯‘
    for sent, trans in SENTENCE_TRANSLATIONS.items():
        if sent in text:
            text = text.replace(sent, trans)
    
    # å†ç”¨å•è¯çº§ç¿»è¯‘
    for word, trans in WORD_TRANSLATIONS.items():
        # é¿å…é‡å¤ç¿»è¯‘
        if word not in text and trans in text:
            continue
        # ä½¿ç”¨è¯è¾¹ç•ŒåŒ¹é…
        pattern = r'\b' + re.escape(word) + r'\b'
        text = re.sub(pattern, trans, text, flags=re.IGNORECASE)
    
    return text

def main():
    input_file = Path(r'd:\Users\Source\Ai-Gameplay-Bot\logs\en.srt')
    output_file = Path(r'd:\Users\Source\Ai-Gameplay-Bot\logs\zh-cn.srt')
    
    if not input_file.exists():
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨")
        return
    
    with open(input_file, 'r', encoding='utf-8-sig') as f:
        content = f.read()
    
    subtitles = parse_srt(content)
    print(f"ğŸ“– è¯»å–: {len(subtitles)} æ¡å­—å¹•")
    
    translated = []
    for seq, ts, lines in subtitles:
        trans_lines = [translate_line(line) for line in lines]
        translated.append((seq, ts, trans_lines))
    
    with open(output_file, 'w', encoding='utf-8') as f:
        for i, (seq, ts, lines) in enumerate(translated):
            f.write(f"{seq}\n{ts}\n")
            for line in lines:
                f.write(line + "\n")
            if i < len(translated) - 1:
                f.write("\n")
    
    print(f"âœ… å·²ä¿å­˜åˆ°: {output_file.name}")

if __name__ == '__main__':
    main()
